---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: promtail
  namespace: sc
spec:
  selector:
    matchLabels:
      name: promtail
  template:
    metadata:
      labels:
        name: promtail
    spec:
      serviceAccountName: promtail
      securityContext:
        fsGroup: 2000
      containers:
      - name: promtail
        image: grafana/promtail:2.4.1
        args:
        - "-config.file=/etc/promtail/promtail.yaml"
        volumeMounts:
        - name: config
          mountPath: /etc/promtail
        - name: pods
          mountPath: /var/log/pods
          readOnly: true
        - name: docker
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: promtail-config
      - name: pods
        hostPath:
          path: /var/log/pods
      - name: docker
        hostPath:
          path: /var/lib/docker/containers
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: sc
data:
  promtail.yaml: |
    server:
      http_listen_port: 3101
      grpc_listen_port: 0
    positions:
      filename: /tmp/positions.yaml
    clients:
    - url: http://monitoring-service.sc:3100/loki/api/v1/push
    scrape_configs:
    - job_name: kubernetes-pods
      kubernetes_sd_configs:
      - role: pod
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_node_name]
        action: replace
        target_label: __host__
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-exporter
  namespace: sc
spec:
  selector:
    matchLabels:
      app: node-exporter
  template:
    metadata:
      labels:
        app: node-exporter
    spec:
      containers:
      - name: node-exporter
        image: prom/node-exporter
        ports:
        - containerPort: 9100
          name: scrape
        volumeMounts:
        - name: proc
          mountPath: /host/proc
        - name: sys
          mountPath: /host/sys
        - name: rootfs
          mountPath: /host/rootfs
      volumes:
      - name: proc
        hostPath:
          path: /proc
      - name: sys
        hostPath:
          path: /sys
      - name: rootfs
        hostPath:
          path: /
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods", "nodes", "namespaces"]
  verbs: ["get", "watch", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: read-pods-global
subjects:
- kind: ServiceAccount
  name: default
  namespace: sc
roleRef:
  kind: ClusterRole
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: monitoring-vector-configmap
  namespace: sc
data:
  vector.toml: |

    # GLOBAL

    [api]
    enabled = true
    address = "0.0.0.0:8686"

    # SOURCES

    [sources.log_file]
    type = "file"
    include = ["/var/log/*.log"]

    [sources.kubernetes_logs]
    type = "kubernetes_logs"
    auto_partial_merge = true
    self_node_name = "${VECTOR_SELF_NODE_NAME}"


    [sources.prometheus_metrics]
    type = "prometheus_scrape"
    endpoints = ["http://monitoring-service.sc:8686/metrics"]


    # SINKS

    [sinks.console]
    inputs = ["log_file"]
    target = "stdout"
    type = "console"
    encoding.codec = "json"

    [sinks.prometheus]
    type = "prometheus_exporter"
    inputs = ["prometheus_metrics"]
    address = "0.0.0.0:9283"
    default_namespace = "sc"

    [sinks.loki]
    type = "loki"
    inputs = ["kubernetes_logs"]
    endpoint = "http://monitoring-service.sc:3100"
    encoding.codec = "json"
    labels = { host = "{{ host }}" }
 
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: loki-config
  namespace: sc
data:
  loki-local-config.yaml: |
    auth_enabled: false
    server:
      http_listen_port: 3100
    ingester:
      wal:
        enabled: false
      lifecycler:
        address: 127.0.0.1
        ring:
          kvstore:
            store: inmemory
          replication_factor: 1
        final_sleep: 0s
      chunk_idle_period: 1h       # Any chunk not receiving new logs in this time will be flushed
      max_chunk_age: 1h           # All chunks will be flushed when they hit this age, default is 1h
      chunk_target_size: 1048576  # Loki will attempt to build chunks up to 1.5MB, flushing first if chunk_idle_period or max_chunk_age is reached first
      chunk_retain_period: 30s    # Must be less than or equal to chunk_idle_period
      max_transfer_retries: 0     # Chunk transfers disabled
    schema_config:
      configs:
        - from: 2020-05-15
          store: boltdb-shipper
          object_store: filesystem
          schema: v11
          index:
            prefix: index_
            period: 24h
    storage_config:
      boltdb_shipper:
        active_index_directory: /loki/boltdb-shipper-active
        cache_location: /loki/boltdb-shipper-cache
        cache_ttl: 24h          # Can be increased for faster performance over longer query periods, uses more disk space
        shared_store: filesystem
    compactor:
      working_directory: /loki/boltdb-shipper-compactor
      shared_store: filesystem
    limits_config:
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
    chunk_store_config:
      max_look_back_period: 0s
    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: sc
data:
  prometheus.yml: |
    global:
      scrape_interval:     15s
      evaluation_interval: 15s
    scrape_configs:
      - job_name: 'vector'
        static_configs:
          - targets: ['monitoring-service.sc:9283', 'alice-service.sc:9283', 'bob-service.sc:9283', 'charlie-service.sc:9283','dave-service.sc:9283','eve-service.sc:9283']
      - job_name: 'kube-state-metrics'
        static_configs:
          - targets: ['kube-state-metrics.sc.svc.cluster.local:8080']

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: sc
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        url: http://localhost:9090
        access: proxy
        isDefault: true
      - name: Loki
        type: loki
        url: http://localhost:3100
        access: proxy
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards-provisioning
  namespace: sc
data:
  dashboards.yaml: |-
    apiVersion: 1
    providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /etc/grafana/dashboards/default
---
apiVersion: v1
kind: Service
metadata:
  name: monitoring-service
  namespace: sc
spec:
  type: NodePort
  selector:
    app: monitoring-pod
  ports:
    - name: grafana
      port: 3000
      targetPort: 3000
      nodePort: 30000
    - name: prometheus
      port: 9090
      targetPort: 9090
      nodePort: 30010
    - name: loki
      port: 3100
      targetPort: 3100
      nodePort: 30020
    - name: vector-api
      port: 8686
      targetPort: 8686
      nodePort: 30030
    - name: vector-prometheus
      port: 9283
      targetPort: 9283
      nodePort: 30040
---
apiVersion: v1
kind: Pod
metadata:
  name: monitoring
  namespace: sc
  labels:
    app: monitoring-pod
spec:
  nodeSelector:
    pod: monitoring
  containers:
    - name: vector
      image: timberio/vector:nightly-alpine
      imagePullPolicy: IfNotPresent
      resources:
        limits:
          memory: "4096Mi"
          cpu: "1500m"
        requests:
          memory: "4096Mi"
          cpu: "1500m"
      ports:
        - containerPort: 8686
      env:
        - name: VECTOR_SELF_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
      volumeMounts:
        - name: vector-config
          mountPath: /etc/vector
        - name: vector-data
          mountPath: /var/log
    - name: loki
      image: grafana/loki:2.4.1
      imagePullPolicy: IfNotPresent
      resources:
        limits:
          memory: "4096Mi"
          cpu: "1500m"
        requests:
          memory: "4096Mi"
          cpu: "1500m"
      ports:
        - containerPort: 3100
      args:
        - -config.file=/etc/loki/loki-local-config.yaml
      volumeMounts:
        - name: loki-data
          mountPath: /loki
        - name: loki-config
          mountPath: /etc/loki
    - name: prometheus
      image: prom/prometheus:v2.45.0
      imagePullPolicy: IfNotPresent
      resources:
        limits:
          memory: "4096Mi"
          cpu: "2000m"
        requests:
          memory: "4096Mi"
          cpu: "2000m"
      ports:
        - containerPort: 9090
      volumeMounts:
        - name: prometheus-data
          mountPath: /prometheus
        - name: prometheus-config
          mountPath: /etc/prometheus/prometheus.yml
          subPath: prometheus.yml
    - name: grafana
      image: grafana/grafana:10.0.1
      imagePullPolicy: IfNotPresent
      resources:
        limits:
          memory: "8192Mi"
          cpu: "2000m"
        requests:
          memory: "8192Mi"
          cpu: "2000m"
      ports:
        - containerPort: 3000
      volumeMounts:
        - name: grafana-data
          mountPath: /var/lib/grafana
        - name: grafana-config
          mountPath: /etc/grafana/provisioning/datasources
        - name: grafana-dashboard
          mountPath: /etc/grafana/provisioning/dashboards/
        - name: grafana-dashboards-provisioning
          mountPath: /etc/grafana/provisioning/dashboards
  volumes:
    - name: vector-config
      configMap:
        name: monitoring-vector-configmap
    - name: vector-data
      persistentVolumeClaim:
        claimName: monitoring-claim-vector
    - name: loki-data
      persistentVolumeClaim:
        claimName: monitoring-claim-loki
    - name: loki-config
      configMap:
        name: loki-config
    - name: prometheus-data
      persistentVolumeClaim:
        claimName: monitoring-claim-prometheus
    - name: prometheus-config
      configMap:
        name: prometheus-config
    - name: grafana-data
      persistentVolumeClaim:
        claimName: monitoring-claim-grafana
    - name: grafana-config
      configMap:
        name: grafana-config
    - name: grafana-dashboard
      configMap:
        name: grafana-dashboard
    - name: grafana-dashboards-provisioning
      configMap:
        name: grafana-dashboards-provisioning
